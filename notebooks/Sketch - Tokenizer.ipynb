{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python377jvsc74a57bd098b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f",
   "display_name": "Python 3.7.7 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "from dataset import load_data, REDataset\n",
    "from config import Config, PreTrainedType, PreProcessType\n",
    "from tokenization import SpecialToken\n",
    "from utils import load_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Load raw data...\tpreprocessing for 'EntitySeparation'...\tdone!\n",
      "Load Tokenizer...\tdone!\n",
      "Apply Tokenization...\tdone!\n"
     ]
    }
   ],
   "source": [
    "data = REDataset(preprocess_type=PreProcessType.ES,device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[100, 102, 0, 101, 103]"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "data.tokenizer.all_special_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " '랜',\n",
       " '##드',\n",
       " '##로',\n",
       " '##버',\n",
       " '[SEP]',\n",
       " '자',\n",
       " '##동차',\n",
       " '[SEP]',\n",
       " '영국',\n",
       " '##에서',\n",
       " '사',\n",
       " '##용',\n",
       " '##되는',\n",
       " '스',\n",
       " '##포츠',\n",
       " '유',\n",
       " '##틸',\n",
       " '##리',\n",
       " '##티',\n",
       " '자',\n",
       " '##동차',\n",
       " '##의',\n",
       " '브',\n",
       " '##랜드',\n",
       " '##로는',\n",
       " '랜',\n",
       " '##드',\n",
       " '##로',\n",
       " '##버',\n",
       " '(',\n",
       " 'Land',\n",
       " 'Rover',\n",
       " ')',\n",
       " '와',\n",
       " '지',\n",
       " '##프',\n",
       " '(',\n",
       " 'Je',\n",
       " '##ep',\n",
       " ')',\n",
       " '가',\n",
       " '있으며',\n",
       " ',',\n",
       " '이',\n",
       " '브',\n",
       " '##랜드',\n",
       " '##들은',\n",
       " '자',\n",
       " '##동차',\n",
       " '##의',\n",
       " '종',\n",
       " '##류',\n",
       " '##를',\n",
       " '일',\n",
       " '##컫',\n",
       " '##는',\n",
       " '말',\n",
       " '##로',\n",
       " '사',\n",
       " '##용',\n",
       " '##되',\n",
       " '##기도',\n",
       " '한다',\n",
       " '.',\n",
       " '[SEP]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]']"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "data.tokenizer.convert_ids_to_tokens(data[0][0]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-f2a543ce2583>, line 49)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-f2a543ce2583>\"\u001b[0;36m, line \u001b[0;32m49\u001b[0m\n\u001b[0;31m    if\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class REDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str = Config.Train,\n",
    "        preprocess_type: str = PreProcessType.Base,\n",
    "        device: str = Config.Device,\n",
    "    ):\n",
    "        self.tokenizer = load_tokenizer(type=tokenization_type)\n",
    "        self.enc = LabelEncoder()\n",
    "        raw = self._load_raw(root)\n",
    "        self.sentences = self._tokenize(raw)\n",
    "        self.labels = raw[\"label\"].tolist()\n",
    "        self.device = device\n",
    "\n",
    "    def __getitem__(self, idx) -> Tuple[dict, torch.Tensor]:\n",
    "        sentence = {\n",
    "            key: torch.as_tensor(val[idx]).to(self.device)\n",
    "            for key, val in self.sentences.items()\n",
    "        }\n",
    "        label = torch.as_tensor(self.labels[idx]).to(self.device)\n",
    "        return sentence, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def _load_raw(self, root):\n",
    "        print(\"Load raw data...\", end=\"\\t\")\n",
    "        raw = pd.read_csv(root, sep=\"\\t\", header=None)\n",
    "        raw.columns = COLUMNS\n",
    "        raw = raw.drop(\"id\", axis=1)\n",
    "        raw[\"label\"] = raw[\"label\"].apply(lambda x: self.enc.transform(x))\n",
    "        print(\"done!\")\n",
    "        return raw\n",
    "\n",
    "    def _tokenize(self, data):\n",
    "        print(\"Apply Tokenization...\", end=\"\\t\")\n",
    "        data_tokenized = self.tokenizer(\n",
    "            data[\"relation_state\"].tolist(),\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=128,\n",
    "            add_special_tokens=True,\n",
    "        )\n",
    "        print(\"done!\")\n",
    "        return data_tokenized\n",
    "\n",
    "    def _text_preprocess(self, data, preprocess_type):\n",
    "        if preprocess_type == PreProcessType.Base:\n",
    "            data['']\n",
    "            return data\n",
    "        elif preprocess_type == PreProcessType.ES:\n",
    "            return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer(\n",
    "    data['relation_state'],\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=128,\n",
    "    add_special_tokens=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(PreTrainedType.BertMultiLingual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['num_tokens'] = data['relation_state'].apply(lambda x: len(tokenizer.tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['relation_state'] = data['e1'] + SpecialToken.SEP + data['e2'] + SpecialToken.SEP + data['relation_state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'input_ids': [101, 9167, 15001, 11261, 41605, 102, 9651, 99183, 102, 50266, 11489, 9405, 24974, 24683, 9477, 90578, 9625, 119376, 12692, 45725, 9651, 99183, 10459, 9376, 42771, 70186, 9167, 15001, 11261, 41605, 113, 12001, 57836, 114, 9590, 9706, 28396, 113, 13796, 19986, 114, 8843, 22634, 117, 9638, 9376, 42771, 22879, 9651, 99183, 10459, 9684, 46520, 11513, 9641, 119298, 11018, 9251, 11261, 9405, 24974, 118800, 27792, 16139, 119, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "tokenizer(data['relation_state'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = list(map(lambda x: tokenizer(x), data['relation_state']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " '랜',\n",
       " '##드',\n",
       " '##로',\n",
       " '##버',\n",
       " '[SEP]',\n",
       " '자',\n",
       " '##동차',\n",
       " '[SEP]',\n",
       " '영국',\n",
       " '##에서',\n",
       " '사',\n",
       " '##용',\n",
       " '##되는',\n",
       " '스',\n",
       " '##포츠',\n",
       " '유',\n",
       " '##틸',\n",
       " '##리',\n",
       " '##티',\n",
       " '자',\n",
       " '##동차',\n",
       " '##의',\n",
       " '브',\n",
       " '##랜드',\n",
       " '##로는',\n",
       " '랜',\n",
       " '##드',\n",
       " '##로',\n",
       " '##버',\n",
       " '(',\n",
       " 'Land',\n",
       " 'Rover',\n",
       " ')',\n",
       " '와',\n",
       " '지',\n",
       " '##프',\n",
       " '(',\n",
       " 'Je',\n",
       " '##ep',\n",
       " ')',\n",
       " '가',\n",
       " '있으며',\n",
       " ',',\n",
       " '이',\n",
       " '브',\n",
       " '##랜드',\n",
       " '##들은',\n",
       " '자',\n",
       " '##동차',\n",
       " '##의',\n",
       " '종',\n",
       " '##류',\n",
       " '##를',\n",
       " '일',\n",
       " '##컫',\n",
       " '##는',\n",
       " '말',\n",
       " '##로',\n",
       " '사',\n",
       " '##용',\n",
       " '##되',\n",
       " '##기도',\n",
       " '한다',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(output[0].input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                         relation_state        e1  e1_start  \\\n",
       "0     영국에서 사용되는 스포츠 유틸리티 자동차의 브랜드로는 랜드로버(Land Rover)...      랜드로버        30   \n",
       "1     선거에서 민주당은 해산 전 의석인 230석에 한참 못 미치는 57석(지역구 27석,...       민주당         5   \n",
       "2     유럽 축구 연맹(UEFA) 집행위원회는 2014년 1월 24일에 열린 회의를 통해 ...  유럽 축구 연맹         0   \n",
       "3     용병 공격수 챠디의 부진과 시즌 초 활약한 강수일의 침체, 시즌 중반에 영입한 세르...       강수일        24   \n",
       "4     람캄행 왕은 1237년에서 1247년 사이 수코타이의 왕 퍼쿤 씨 인트라팃과 쓰엉 ...       람캄행         0   \n",
       "...                                                 ...       ...       ...   \n",
       "8995  2002년 FIFA 월드컵 사우디아라비아와의 1차전에서 독일은 8-0으로 승리하였는...   사우디아라비아        15   \n",
       "8996  일본의 2대 메이커인 토요타와 닛산은 시장 점유율을 높이기 위한 신차 개발을 계속하...       토요타        12   \n",
       "8997  방호의의 손자 방덕룡(方德龍)은 1588년(선조 21년) 무과에 급제하고 낙안군수로...       방덕룡         8   \n",
       "8998  LG전자는 올해 초 국내시장에 출시한 2020년형 ‘LG 그램’ 시리즈를 이달부터 ...      LG전자         0   \n",
       "8999  전남도의회 안전건설소방위원회 차영수 의원(강진1)은 지난 14일 설 명절을 앞두고 ...       차영수        16   \n",
       "\n",
       "      e1_end              e2  e2_start  e2_end  label  num_tokens  \n",
       "0         33             자동차        19      21     17          56  \n",
       "1          7             27석        42      44      0          44  \n",
       "2          7            UEFA         9      12      6          50  \n",
       "3         26             공격수         3       5      2         108  \n",
       "4          2       퍼쿤 씨 인트라팃        32      40      8          32  \n",
       "...      ...             ...       ...     ...    ...         ...  \n",
       "8995      21           2002년         0       4      0          34  \n",
       "8996      14              일본         0       1      9          32  \n",
       "8997      10  선무원종공신(宣武原從功臣)        93     106      2          84  \n",
       "8998       3              북미        46      47      0          44  \n",
       "8999      18              의원        20      21      2          72  \n",
       "\n",
       "[9000 rows x 9 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>relation_state</th>\n      <th>e1</th>\n      <th>e1_start</th>\n      <th>e1_end</th>\n      <th>e2</th>\n      <th>e2_start</th>\n      <th>e2_end</th>\n      <th>label</th>\n      <th>num_tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>영국에서 사용되는 스포츠 유틸리티 자동차의 브랜드로는 랜드로버(Land Rover)...</td>\n      <td>랜드로버</td>\n      <td>30</td>\n      <td>33</td>\n      <td>자동차</td>\n      <td>19</td>\n      <td>21</td>\n      <td>17</td>\n      <td>56</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>선거에서 민주당은 해산 전 의석인 230석에 한참 못 미치는 57석(지역구 27석,...</td>\n      <td>민주당</td>\n      <td>5</td>\n      <td>7</td>\n      <td>27석</td>\n      <td>42</td>\n      <td>44</td>\n      <td>0</td>\n      <td>44</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>유럽 축구 연맹(UEFA) 집행위원회는 2014년 1월 24일에 열린 회의를 통해 ...</td>\n      <td>유럽 축구 연맹</td>\n      <td>0</td>\n      <td>7</td>\n      <td>UEFA</td>\n      <td>9</td>\n      <td>12</td>\n      <td>6</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>용병 공격수 챠디의 부진과 시즌 초 활약한 강수일의 침체, 시즌 중반에 영입한 세르...</td>\n      <td>강수일</td>\n      <td>24</td>\n      <td>26</td>\n      <td>공격수</td>\n      <td>3</td>\n      <td>5</td>\n      <td>2</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>람캄행 왕은 1237년에서 1247년 사이 수코타이의 왕 퍼쿤 씨 인트라팃과 쓰엉 ...</td>\n      <td>람캄행</td>\n      <td>0</td>\n      <td>2</td>\n      <td>퍼쿤 씨 인트라팃</td>\n      <td>32</td>\n      <td>40</td>\n      <td>8</td>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8995</th>\n      <td>2002년 FIFA 월드컵 사우디아라비아와의 1차전에서 독일은 8-0으로 승리하였는...</td>\n      <td>사우디아라비아</td>\n      <td>15</td>\n      <td>21</td>\n      <td>2002년</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>34</td>\n    </tr>\n    <tr>\n      <th>8996</th>\n      <td>일본의 2대 메이커인 토요타와 닛산은 시장 점유율을 높이기 위한 신차 개발을 계속하...</td>\n      <td>토요타</td>\n      <td>12</td>\n      <td>14</td>\n      <td>일본</td>\n      <td>0</td>\n      <td>1</td>\n      <td>9</td>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th>8997</th>\n      <td>방호의의 손자 방덕룡(方德龍)은 1588년(선조 21년) 무과에 급제하고 낙안군수로...</td>\n      <td>방덕룡</td>\n      <td>8</td>\n      <td>10</td>\n      <td>선무원종공신(宣武原從功臣)</td>\n      <td>93</td>\n      <td>106</td>\n      <td>2</td>\n      <td>84</td>\n    </tr>\n    <tr>\n      <th>8998</th>\n      <td>LG전자는 올해 초 국내시장에 출시한 2020년형 ‘LG 그램’ 시리즈를 이달부터 ...</td>\n      <td>LG전자</td>\n      <td>0</td>\n      <td>3</td>\n      <td>북미</td>\n      <td>46</td>\n      <td>47</td>\n      <td>0</td>\n      <td>44</td>\n    </tr>\n    <tr>\n      <th>8999</th>\n      <td>전남도의회 안전건설소방위원회 차영수 의원(강진1)은 지난 14일 설 명절을 앞두고 ...</td>\n      <td>차영수</td>\n      <td>16</td>\n      <td>18</td>\n      <td>의원</td>\n      <td>20</td>\n      <td>21</td>\n      <td>2</td>\n      <td>72</td>\n    </tr>\n  </tbody>\n</table>\n<p>9000 rows × 9 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "tokenizer.unk_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "PreTrainedTokenizer(name_or_path='bert-base-multilingual-cased', vocab_size=119547, model_max_len=512, is_fast=False, padding_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "tokenizer()"
   ]
  }
 ]
}