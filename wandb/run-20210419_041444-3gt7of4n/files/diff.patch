diff --git a/inference.py b/inference.py
index 049d0ce..12fb8a7 100644
--- a/inference.py
+++ b/inference.py
@@ -69,7 +69,7 @@ def get_model_pretrained_type(load_state_dict: str):
 
 
 if __name__ == "__main__":
-    MODELNAME = "VanillaBert_bert-base-multilingual-cased_20210418164452/VanillaBert_bert-base-multilingual-cased_ep(02)acc(0.4878)loss(0.0048)id(20210418164452).pth"
+    MODELNAME = "BertForSequenceClassification_bert-base-multilingual-cased_20210419121332/BertForSequenceClassification_bert-base-multilingual-cased_ep(16)acc(0.7200)loss(0.0024)id(20210419121332).pth"
     LOAD_STATE_DICT = os.path.join(Config.CheckPoint, MODELNAME)
 
     parser = argparse.ArgumentParser()
@@ -77,7 +77,7 @@ if __name__ == "__main__":
     parser.add_argument("--num-classes", type=int, default=Config.NumClasses)
     parser.add_argument("--pooler-idx", type=int, default=0)
     parser.add_argument("--data-root", type=str, default=Config.Test)
-    parser.add_argument("--tokenization-type", type=str, default=PreProcessType.Base)
+    parser.add_argument("--tokenization-type", type=str, default=PreProcessType.ES)
     parser.add_argument("--device", type=str, default=Config.Device)
     parser.add_argument("--save-path", type=str, default=Config.SavePath)
     args = parser.parse_args()
diff --git a/notebooks/Sketch - Model.ipynb b/notebooks/Sketch - Model.ipynb
index d7a7e29..666420e 100644
--- a/notebooks/Sketch - Model.ipynb	
+++ b/notebooks/Sketch - Model.ipynb	
@@ -23,14 +23,15 @@
  "cells": [
   {
    "cell_type": "code",
-   "execution_count": 30,
+   "execution_count": 33,
    "metadata": {},
    "outputs": [],
    "source": [
     "import sys\n",
     "import torch\n",
     "from torch.utils.data import DataLoader\n",
-    "from transformers import BertTokenizer, BertTokenizerFast, BertModel, BertConfig, DataCollatorForLanguageModeling, TrainingArguments, Trainer, DataCollatorForWholeWordMask\n",
+    "from torch import nn\n",
+    "from transformers import BertTokenizer, BertTokenizerFast, BertForSequenceClassification, BertModel, BertConfig\n",
     "from tokenizers import BertWordPieceTokenizer\n",
     "\n",
     "\n",
@@ -42,327 +43,89 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 15,
+   "execution_count": 6,
    "metadata": {},
-   "outputs": [
-    {
-     "output_type": "stream",
-     "name": "stdout",
-     "text": [
-      "Load Tokenizer...\tdone!\n",
-      "Load raw data...\tdone!\n",
-      "Apply Tokenization...\tdone!\n"
-     ]
-    }
-   ],
+   "outputs": [],
    "source": [
-    "data = REDataset()"
+    "config = BertConfig.from_pretrained(PreTrainedType.MultiLingual)\n",
+    "config.num_labels = 42"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 22,
+   "execution_count": 7,
    "metadata": {},
    "outputs": [
     {
      "output_type": "stream",
-     "name": "stdout",
+     "name": "stderr",
      "text": [
-      "CUDA\n"
+      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
+      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
+      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
+      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
+      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
      ]
     }
    ],
    "source": [
-    "model = BertModel.from_pretrained(PreTrainedType.MultiLingual)\n",
-    "model.cuda()\n",
-    "print('CUDA')"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 23,
-   "metadata": {},
-   "outputs": [],
-   "source": [
-    "sent, label = data[0]"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 32,
-   "metadata": {},
-   "outputs": [],
-   "source": [
-    "temp = DataLoader(data, batch_size=4)"
+    "model = BertForSequenceClassification.from_pretrained(PreTrainedType.MultiLingual, config=config)"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 33,
+   "execution_count": 17,
    "metadata": {},
-   "outputs": [],
-   "source": [
-    "for sents, labels in temp:\n",
-    "    break"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 43,
-   "metadata": {
-    "tags": []
-   },
    "outputs": [
     {
      "output_type": "stream",
      "name": "stdout",
      "text": [
-      "embeddings.word_embeddings.weight\nembeddings.position_embeddings.weight\nembeddings.token_type_embeddings.weight\nembeddings.LayerNorm.weight\nembeddings.LayerNorm.bias\nencoder.layer.0.attention.self.query.weight\nencoder.layer.0.attention.self.query.bias\nencoder.layer.0.attention.self.key.weight\nencoder.layer.0.attention.self.key.bias\nencoder.layer.0.attention.self.value.weight\nencoder.layer.0.attention.self.value.bias\nencoder.layer.0.attention.output.dense.weight\nencoder.layer.0.attention.output.dense.bias\nencoder.layer.0.attention.output.LayerNorm.weight\nencoder.layer.0.attention.output.LayerNorm.bias\nencoder.layer.0.intermediate.dense.weight\nencoder.layer.0.intermediate.dense.bias\nencoder.layer.0.output.dense.weight\nencoder.layer.0.output.dense.bias\nencoder.layer.0.output.LayerNorm.weight\nencoder.layer.0.output.LayerNorm.bias\nencoder.layer.1.attention.self.query.weight\nencoder.layer.1.attention.self.query.bias\nencoder.layer.1.attention.self.key.weight\nencoder.layer.1.attention.self.key.bias\nencoder.layer.1.attention.self.value.weight\nencoder.layer.1.attention.self.value.bias\nencoder.layer.1.attention.output.dense.weight\nencoder.layer.1.attention.output.dense.bias\nencoder.layer.1.attention.output.LayerNorm.weight\nencoder.layer.1.attention.output.LayerNorm.bias\nencoder.layer.1.intermediate.dense.weight\nencoder.layer.1.intermediate.dense.bias\nencoder.layer.1.output.dense.weight\nencoder.layer.1.output.dense.bias\nencoder.layer.1.output.LayerNorm.weight\nencoder.layer.1.output.LayerNorm.bias\nencoder.layer.2.attention.self.query.weight\nencoder.layer.2.attention.self.query.bias\nencoder.layer.2.attention.self.key.weight\nencoder.layer.2.attention.self.key.bias\nencoder.layer.2.attention.self.value.weight\nencoder.layer.2.attention.self.value.bias\nencoder.layer.2.attention.output.dense.weight\nencoder.layer.2.attention.output.dense.bias\nencoder.layer.2.attention.output.LayerNorm.weight\nencoder.layer.2.attention.output.LayerNorm.bias\nencoder.layer.2.intermediate.dense.weight\nencoder.layer.2.intermediate.dense.bias\nencoder.layer.2.output.dense.weight\nencoder.layer.2.output.dense.bias\nencoder.layer.2.output.LayerNorm.weight\nencoder.layer.2.output.LayerNorm.bias\nencoder.layer.3.attention.self.query.weight\nencoder.layer.3.attention.self.query.bias\nencoder.layer.3.attention.self.key.weight\nencoder.layer.3.attention.self.key.bias\nencoder.layer.3.attention.self.value.weight\nencoder.layer.3.attention.self.value.bias\nencoder.layer.3.attention.output.dense.weight\nencoder.layer.3.attention.output.dense.bias\nencoder.layer.3.attention.output.LayerNorm.weight\nencoder.layer.3.attention.output.LayerNorm.bias\nencoder.layer.3.intermediate.dense.weight\nencoder.layer.3.intermediate.dense.bias\nencoder.layer.3.output.dense.weight\nencoder.layer.3.output.dense.bias\nencoder.layer.3.output.LayerNorm.weight\nencoder.layer.3.output.LayerNorm.bias\nencoder.layer.4.attention.self.query.weight\nencoder.layer.4.attention.self.query.bias\nencoder.layer.4.attention.self.key.weight\nencoder.layer.4.attention.self.key.bias\nencoder.layer.4.attention.self.value.weight\nencoder.layer.4.attention.self.value.bias\nencoder.layer.4.attention.output.dense.weight\nencoder.layer.4.attention.output.dense.bias\nencoder.layer.4.attention.output.LayerNorm.weight\nencoder.layer.4.attention.output.LayerNorm.bias\nencoder.layer.4.intermediate.dense.weight\nencoder.layer.4.intermediate.dense.bias\nencoder.layer.4.output.dense.weight\nencoder.layer.4.output.dense.bias\nencoder.layer.4.output.LayerNorm.weight\nencoder.layer.4.output.LayerNorm.bias\nencoder.layer.5.attention.self.query.weight\nencoder.layer.5.attention.self.query.bias\nencoder.layer.5.attention.self.key.weight\nencoder.layer.5.attention.self.key.bias\nencoder.layer.5.attention.self.value.weight\nencoder.layer.5.attention.self.value.bias\nencoder.layer.5.attention.output.dense.weight\nencoder.layer.5.attention.output.dense.bias\nencoder.layer.5.attention.output.LayerNorm.weight\nencoder.layer.5.attention.output.LayerNorm.bias\nencoder.layer.5.intermediate.dense.weight\nencoder.layer.5.intermediate.dense.bias\nencoder.layer.5.output.dense.weight\nencoder.layer.5.output.dense.bias\nencoder.layer.5.output.LayerNorm.weight\nencoder.layer.5.output.LayerNorm.bias\nencoder.layer.6.attention.self.query.weight\nencoder.layer.6.attention.self.query.bias\nencoder.layer.6.attention.self.key.weight\nencoder.layer.6.attention.self.key.bias\nencoder.layer.6.attention.self.value.weight\nencoder.layer.6.attention.self.value.bias\nencoder.layer.6.attention.output.dense.weight\nencoder.layer.6.attention.output.dense.bias\nencoder.layer.6.attention.output.LayerNorm.weight\nencoder.layer.6.attention.output.LayerNorm.bias\nencoder.layer.6.intermediate.dense.weight\nencoder.layer.6.intermediate.dense.bias\nencoder.layer.6.output.dense.weight\nencoder.layer.6.output.dense.bias\nencoder.layer.6.output.LayerNorm.weight\nencoder.layer.6.output.LayerNorm.bias\nencoder.layer.7.attention.self.query.weight\nencoder.layer.7.attention.self.query.bias\nencoder.layer.7.attention.self.key.weight\nencoder.layer.7.attention.self.key.bias\nencoder.layer.7.attention.self.value.weight\nencoder.layer.7.attention.self.value.bias\nencoder.layer.7.attention.output.dense.weight\nencoder.layer.7.attention.output.dense.bias\nencoder.layer.7.attention.output.LayerNorm.weight\nencoder.layer.7.attention.output.LayerNorm.bias\nencoder.layer.7.intermediate.dense.weight\nencoder.layer.7.intermediate.dense.bias\nencoder.layer.7.output.dense.weight\nencoder.layer.7.output.dense.bias\nencoder.layer.7.output.LayerNorm.weight\nencoder.layer.7.output.LayerNorm.bias\nencoder.layer.8.attention.self.query.weight\nencoder.layer.8.attention.self.query.bias\nencoder.layer.8.attention.self.key.weight\nencoder.layer.8.attention.self.key.bias\nencoder.layer.8.attention.self.value.weight\nencoder.layer.8.attention.self.value.bias\nencoder.layer.8.attention.output.dense.weight\nencoder.layer.8.attention.output.dense.bias\nencoder.layer.8.attention.output.LayerNorm.weight\nencoder.layer.8.attention.output.LayerNorm.bias\nencoder.layer.8.intermediate.dense.weight\nencoder.layer.8.intermediate.dense.bias\nencoder.layer.8.output.dense.weight\nencoder.layer.8.output.dense.bias\nencoder.layer.8.output.LayerNorm.weight\nencoder.layer.8.output.LayerNorm.bias\nencoder.layer.9.attention.self.query.weight\nencoder.layer.9.attention.self.query.bias\nencoder.layer.9.attention.self.key.weight\nencoder.layer.9.attention.self.key.bias\nencoder.layer.9.attention.self.value.weight\nencoder.layer.9.attention.self.value.bias\nencoder.layer.9.attention.output.dense.weight\nencoder.layer.9.attention.output.dense.bias\nencoder.layer.9.attention.output.LayerNorm.weight\nencoder.layer.9.attention.output.LayerNorm.bias\nencoder.layer.9.intermediate.dense.weight\nencoder.layer.9.intermediate.dense.bias\nencoder.layer.9.output.dense.weight\nencoder.layer.9.output.dense.bias\nencoder.layer.9.output.LayerNorm.weight\nencoder.layer.9.output.LayerNorm.bias\nencoder.layer.10.attention.self.query.weight\nencoder.layer.10.attention.self.query.bias\nencoder.layer.10.attention.self.key.weight\nencoder.layer.10.attention.self.key.bias\nencoder.layer.10.attention.self.value.weight\nencoder.layer.10.attention.self.value.bias\nencoder.layer.10.attention.output.dense.weight\nencoder.layer.10.attention.output.dense.bias\nencoder.layer.10.attention.output.LayerNorm.weight\nencoder.layer.10.attention.output.LayerNorm.bias\nencoder.layer.10.intermediate.dense.weight\nencoder.layer.10.intermediate.dense.bias\nencoder.layer.10.output.dense.weight\nencoder.layer.10.output.dense.bias\nencoder.layer.10.output.LayerNorm.weight\nencoder.layer.10.output.LayerNorm.bias\nencoder.layer.11.attention.self.query.weight\nencoder.layer.11.attention.self.query.bias\nencoder.layer.11.attention.self.key.weight\nencoder.layer.11.attention.self.key.bias\nencoder.layer.11.attention.self.value.weight\nencoder.layer.11.attention.self.value.bias\nencoder.layer.11.attention.output.dense.weight\nencoder.layer.11.attention.output.dense.bias\nencoder.layer.11.attention.output.LayerNorm.weight\nencoder.layer.11.attention.output.LayerNorm.bias\nencoder.layer.11.intermediate.dense.weight\nencoder.layer.11.intermediate.dense.bias\nencoder.layer.11.output.dense.weight\nencoder.layer.11.output.dense.bias\nencoder.layer.11.output.LayerNorm.weight\nencoder.layer.11.output.LayerNorm.bias\npooler.dense.weight\npooler.dense.bias\n"
+      "Load raw data...\tpreprocessing for 'Base'...\tdone!\n",
+      "Load Tokenizer...\tdone!\n",
+      "Apply Tokenization...\tdone!\n"
      ]
     }
    ],
    "source": [
-    "for name, param in model.named_parameters():\n",
-    "    print(name)"
+    "dataset = REDataset(device='cpu')"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 44,
+   "execution_count": 19,
    "metadata": {},
    "outputs": [],
    "source": [
-    "outputs = model(**sents)"
+    "loader = DataLoader(dataset, batch_size=4)"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 47,
+   "execution_count": 20,
    "metadata": {},
-   "outputs": [
-    {
-     "output_type": "execute_result",
-     "data": {
-      "text/plain": [
-       "tensor([[ 0.1927, -0.1140,  0.1545,  ..., -0.1682,  0.0765,  0.1716],\n",
-       "        [ 0.2937, -0.0188,  0.3508,  ..., -0.1271,  0.1640,  0.1288],\n",
-       "        [ 0.2748, -0.0108,  0.1434,  ..., -0.2278,  0.1751,  0.1524],\n",
-       "        [ 0.3211, -0.1236,  0.1505,  ..., -0.3515,  0.0855,  0.1090]],\n",
-       "       device='cuda:0', grad_fn=<TanhBackward>)"
-      ]
-     },
-     "metadata": {},
-     "execution_count": 47
-    }
-   ],
+   "outputs": [],
    "source": [
-    "outputs.pooler_output"
+    "for sents, labels in loader:\n",
+    "    break"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 26,
+   "execution_count": 24,
    "metadata": {},
    "outputs": [],
    "source": [
-    "tokenizer = BertTokenizer.from_pretrained(PreTrainedType.MultiLingual)\n",
-    "model = BertModel.from_pretrained(PreTrainedType.MultiLingual)\n",
-    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
-    "outputs = model(**inputs)"
+    "output = model.bert(**sents)"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 28,
    "metadata": {},
-   "outputs": [
-    {
-     "output_type": "execute_result",
-     "data": {
-      "text/plain": [
-       "{'input_ids': tensor([[  101, 31178,   117, 15127, 17835, 10124, 21610, 10112,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
-      ]
-     },
-     "metadata": {},
-     "execution_count": 28
-    }
-   ],
-   "source": [
-    "inputs"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 27,
-   "metadata": {},
-   "outputs": [
-    {
-     "output_type": "execute_result",
-     "data": {
-      "text/plain": [
-       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.0569,  0.0820,  0.0835,  ...,  0.2801, -0.1775,  0.2176],\n",
-       "         [-0.1544,  0.0196,  0.2836,  ...,  0.1256, -0.6682, -0.3504],\n",
-       "         [-0.3150, -0.3662,  0.1486,  ..., -0.4080, -0.1579,  0.5193],\n",
-       "         ...,\n",
-       "         [ 0.2656, -0.3016, -0.5070,  ...,  0.3957, -0.2573, -0.0307],\n",
-       "         [ 0.0419, -0.2688, -0.0519,  ...,  0.0905, -0.2808,  0.4754],\n",
-       "         [-0.0482, -0.0653,  0.5319,  ...,  0.2482, -0.2556,  0.2320]]],\n",
-       "       grad_fn=<NativeLayerNormBackward>), pooler_output=tensor([[ 0.3043,  0.0656,  0.2868, -0.1854, -0.1371,  0.5640,  0.2290,  0.2035,\n",
-       "         -0.4755,  0.4321, -0.1011, -0.2794, -0.2156, -0.1278,  0.2104, -0.2177,\n",
-       "          0.7091, -0.0092,  0.1960, -0.4344, -1.0000, -0.1208, -0.3457, -0.2106,\n",
-       "         -0.3447,  0.1666, -0.2626,  0.0763,  0.1979, -0.1930,  0.1113, -1.0000,\n",
-       "          0.5719,  0.7092,  0.2417, -0.0967,  0.2205,  0.2705,  0.2206, -0.3866,\n",
-       "         -0.2654, -0.0908, -0.1782,  0.2449, -0.1834, -0.2459, -0.2140,  0.2404,\n",
-       "         -0.3426,  0.1179,  0.1057,  0.3010,  0.5157,  0.3317,  0.2399,  0.2175,\n",
-       "          0.2240,  0.2683,  0.4356, -0.2385, -0.0456,  0.3629,  0.1646, -0.1851,\n",
-       "         -0.2624, -0.4005,  0.0805, -0.0520,  0.6177, -0.0836, -0.2512, -0.4851,\n",
-       "         -0.1985,  0.1649,  0.0985, -0.2923,  0.3634,  0.3320,  0.0153, -0.2104,\n",
-       "         -0.4136, -0.5783, -0.1684,  0.1689, -0.2240,  0.2801,  0.3826, -0.3551,\n",
-       "          0.0998, -0.0355,  0.2569,  0.5724, -0.3112,  0.4229, -0.1496, -0.2456,\n",
-       "         -0.8750, -0.1602, -0.0548, -0.4673, -0.2646,  0.2305, -0.4092, -0.3055,\n",
-       "         -0.2764, -0.3610,  0.1436,  0.2881, -0.2208,  0.4187,  0.0986, -0.4792,\n",
-       "         -0.2417,  0.0353, -0.2504,  0.9848, -0.3839,  0.2432, -0.1470, -0.2025,\n",
-       "         -0.6647,  1.0000,  0.0622, -0.2237,  0.0261,  0.1622, -0.5495,  0.1246,\n",
-       "          0.3651,  0.2482,  0.1935, -0.1074, -0.1687, -0.3699, -0.8547, -0.3043,\n",
-       "         -0.1884,  0.4046, -0.4027, -0.1811,  0.0900,  0.5893,  0.2102, -0.1112,\n",
-       "         -0.1918, -0.1395,  0.3999, -0.2856,  1.0000,  0.6956, -0.1502, -0.1968,\n",
-       "          0.6121, -0.7360, -0.3531, -0.3941, -0.3081, -0.5198,  0.2791,  0.2303,\n",
-       "          0.1062, -0.0927, -0.2173, -0.2701,  0.3556, -0.6930, -0.2094,  0.3175,\n",
-       "          0.3865,  0.1932, -0.1435,  0.3576,  0.2295, -0.3738, -0.1364,  0.2904,\n",
-       "          0.1059,  0.0604, -0.1614, -0.2196,  0.2279, -0.1517, -0.5941,  0.0728,\n",
-       "         -0.0954, -0.5920,  0.0589,  0.0948, -0.2265,  0.3219, -0.1867,  0.2559,\n",
-       "         -0.3689,  0.3069,  0.3368,  0.1718, -0.4846,  0.2885,  0.3194,  0.4060,\n",
-       "          0.2755,  0.0925,  0.0257,  0.1835, -0.1216, -0.6045,  0.3194,  0.1986,\n",
-       "          0.4257, -0.1904, -0.4402, -0.2187,  0.6396,  0.2475, -0.2939,  0.2539,\n",
-       "          0.1675, -0.2328, -0.0925,  0.2611, -0.2596, -0.4859, -0.3483, -0.2302,\n",
-       "         -0.0218,  0.2362,  0.1635,  0.2058,  0.1731, -0.2866, -0.0898, -0.2424,\n",
-       "          0.0438,  0.3219,  0.0068,  0.8517, -0.2035,  0.2091, -0.5923, -0.1909,\n",
-       "          0.4550, -0.2016,  0.1757,  0.9762,  0.1937, -0.2815,  0.2105,  0.1888,\n",
-       "          0.2187, -0.3279,  0.0148, -0.6671,  0.6836,  0.3191,  0.2665, -1.0000,\n",
-       "          0.3311,  0.2132,  0.4592,  0.2411,  0.2918,  0.1789,  0.3330,  0.9217,\n",
-       "         -0.4782, -0.4738, -0.4140, -0.1910, -0.5208, -0.2714, -0.1918, -0.3573,\n",
-       "         -0.2288, -0.0516, -0.1774,  0.2291,  0.2815, -0.9969,  0.8845,  0.1438,\n",
-       "         -0.1304, -0.0756,  0.2130, -1.0000,  0.2516, -0.0776, -0.3065,  0.3590,\n",
-       "         -0.5855, -0.2876,  0.1530,  0.5008,  0.2514,  0.2050,  0.1557,  0.5015,\n",
-       "         -0.1558,  0.0615,  0.3031, -0.0457,  0.6967,  0.0381,  0.0611,  0.4680,\n",
-       "         -0.0678,  0.3198, -0.2556,  0.2682,  0.4544,  0.2222,  0.0633, -0.3741,\n",
-       "          0.1673, -0.8122,  0.1023, -0.2940, -0.1162, -0.0601,  0.1025, -0.2548,\n",
-       "         -0.3321,  0.0409, -0.4062,  1.0000,  0.1403, -0.3016, -0.3427,  0.5821,\n",
-       "          0.5614, -0.3352, -0.6459,  0.0327,  0.6283,  0.4142,  0.2222,  0.0780,\n",
-       "         -0.2878,  0.3074, -0.1637, -0.2060, -0.0842, -0.4224,  0.2835, -0.1880,\n",
-       "         -0.2443,  0.2380, -0.1876, -0.1785, -0.7875,  0.2686,  0.1177,  0.0872,\n",
-       "          0.1662,  0.1306, -0.3397,  0.5739,  0.3910, -0.2600, -0.3565, -0.2448,\n",
-       "         -0.2191,  0.1073, -0.2423, -0.3978,  0.1823, -0.7387,  0.2329,  0.0347,\n",
-       "         -0.2625, -0.2611,  0.3339, -1.0000, -0.2223,  0.2753, -0.3422,  0.1848,\n",
-       "         -0.3319, -0.1927,  0.1918,  0.2353,  0.0145,  0.1221, -0.4057,  0.2373,\n",
-       "         -0.0698,  0.0989,  0.8409,  0.6095,  0.2038, -0.2398,  0.0613, -0.6216,\n",
-       "         -0.2184,  0.3083,  0.1392, -0.2819,  0.2566,  0.2974,  0.2085, -0.1320,\n",
-       "          0.3083, -0.1026, -0.1864,  0.2943, -0.0022, -0.2316, -0.2110,  0.3194,\n",
-       "         -0.5709,  0.3343,  0.1407,  0.4103,  0.1866,  0.2766, -0.2241, -0.0205,\n",
-       "         -0.2018, -0.0177, -0.2899, -0.2581, -0.1638,  1.0000,  0.2474,  0.4263,\n",
-       "         -0.4723,  0.2702,  0.4071, -0.3153,  0.1808,  0.2557,  0.1144, -0.1909,\n",
-       "          0.1146,  0.0321,  0.2879,  0.3203,  0.3278,  0.5471, -0.3652,  0.7609,\n",
-       "         -0.2042, -0.3800, -0.9974,  0.2021,  0.3233, -0.4707, -0.6077,  0.2039,\n",
-       "         -0.2474, -0.0280, -0.2594,  0.1050,  0.2305, -0.2195,  0.4418, -0.2800,\n",
-       "          1.0000, -0.0257,  0.1084,  0.3168,  0.1780, -0.3480, -0.1121,  0.0415,\n",
-       "          0.3279, -0.1086,  0.1498, -0.9578,  0.3457,  0.1222,  0.2943, -0.0874,\n",
-       "          0.3505, -0.4280,  0.3109, -0.0171, -0.1010, -0.3313,  0.3362, -0.3452,\n",
-       "          0.4997, -0.1310,  0.2467, -0.4295,  0.2869, -0.1318,  0.4260, -0.1889,\n",
-       "          0.2150, -0.2183, -0.2943, -0.2494,  0.0836, -0.4898,  1.0000,  0.0421,\n",
-       "          0.2415, -0.2906,  0.2648, -0.1888,  0.3747,  0.7778, -0.2762,  0.2276,\n",
-       "          0.3803, -0.6896,  0.1929, -0.0527, -0.7243, -0.2473,  0.9679,  0.1282,\n",
-       "          0.5007,  0.3933,  0.3361,  0.1759, -0.0918,  0.1504,  0.9244,  0.1940,\n",
-       "          0.1417,  0.1647, -0.1562, -0.3758, -0.2218,  1.0000,  1.0000, -0.0516,\n",
-       "          0.3961, -0.3864, -0.2542, -0.1881,  0.2163,  0.1820,  0.2830, -0.0210,\n",
-       "         -0.0722, -0.4064, -0.1839, -0.0924, -0.0754, -0.0775,  0.0786, -0.3259,\n",
-       "          0.5661,  0.4157,  0.0554,  0.4771,  0.2689,  0.2565, -0.0690, -0.2386,\n",
-       "          0.5382, -0.2233, -0.0624, -0.3624,  0.0269, -1.0000, -0.2140, -0.1509,\n",
-       "         -0.2286,  0.6007,  0.1375,  0.0469, -0.3019, -0.0717, -0.3982,  0.2483,\n",
-       "          0.2432,  0.0329, -0.2231, -0.4392,  0.3868, -0.5131,  0.2162, -0.4382,\n",
-       "         -0.3031, -0.6810, -0.2271, -0.2154,  0.3583, -0.1915, -0.1791,  0.2861,\n",
-       "          0.3678,  0.2617, -0.3804,  0.3307, -0.3277,  0.0426,  0.3504,  0.2636,\n",
-       "          0.1601, -0.3008, -0.3315, -0.1171, -0.1958, -0.2352,  0.3120, -0.3604,\n",
-       "          0.2353, -0.2525,  0.1616, -0.2502,  0.0130,  0.2569,  0.5073, -0.2590,\n",
-       "          0.5715,  0.3930, -0.0944,  0.4905,  0.0304, -0.3571, -0.2306,  1.0000,\n",
-       "          0.5284,  0.1349,  0.1715, -0.0265,  0.3843,  0.1403,  0.5061, -0.2338,\n",
-       "          0.7803, -0.2514,  0.3416,  0.1551,  0.2806,  0.0447,  0.2339,  0.4760,\n",
-       "          0.7493,  0.2612,  0.3379,  0.3301,  0.2064,  0.3858,  0.3059,  0.2761,\n",
-       "          0.3591,  0.3884, -0.2024,  0.3250, -0.0463, -0.2144, -0.0464, -0.2190,\n",
-       "         -0.2074,  0.1099, -0.1694, -0.2152, -0.1738,  0.3717, -0.2383,  0.4053,\n",
-       "         -0.0803, -0.2693,  0.5765, -0.5285,  0.3224, -0.1825,  0.1612, -0.8612,\n",
-       "          0.1892, -0.1753, -0.5548, -0.1963, -0.4683,  0.1478,  0.2193, -0.2491,\n",
-       "          0.2611, -0.2966,  0.3088, -0.2402, -0.1985,  0.0290, -1.0000,  0.1140,\n",
-       "          0.1509, -0.3366,  0.1799,  0.0772,  0.1558,  0.1888, -0.1982, -0.2855,\n",
-       "         -0.1396,  0.3264, -0.3373,  0.0493,  0.2954, -0.4042, -0.1802,  0.0425,\n",
-       "         -0.1153,  0.1527,  0.3800, -0.4013,  0.2971, -0.3889,  0.2704,  0.0563,\n",
-       "          0.2403, -0.4251, -0.2945,  0.3285, -0.5407, -0.4589, -0.1432,  0.0696,\n",
-       "         -0.1831,  0.1566,  0.1953, -0.1126,  0.4028, -0.2402,  0.3593, -0.2983,\n",
-       "          0.4513, -0.8391, -0.2651, -0.4160, -0.1078,  0.2266,  0.3165,  0.0803,\n",
-       "          0.3080, -0.0270,  0.2792, -0.0789,  0.1682,  0.2307, -0.1635,  0.0978,\n",
-       "         -0.2047,  0.3130, -0.4171,  0.1603, -0.9942, -0.3603,  0.0932,  0.3686,\n",
-       "          0.3737, -0.2416, -0.0927, -0.3871, -0.0990,  0.2526,  0.3764,  0.2848,\n",
-       "          0.2850,  0.3245, -0.2492,  0.0116,  0.7094, -0.3519, -0.1154,  0.4541,\n",
-       "          0.2360,  0.8350,  0.3362,  0.3888,  0.1266, -0.2992,  0.3614,  0.3006]],\n",
-       "       grad_fn=<TanhBackward>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
-      ]
-     },
-     "metadata": {},
-     "execution_count": 27
-    }
-   ],
-   "source": [
-    "outputs"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 3,
-   "metadata": {},
-   "outputs": [
-    {
-     "output_type": "stream",
-     "name": "stdout",
-     "text": [
-      "Load Tokenizer...\tdone!\n"
-     ]
-    }
-   ],
-   "source": [
-    "tokenizer = load_tokenizer(\n",
-    "    type=PreProcessType.Base\n",
-    ")"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 5,
-   "metadata": {},
-   "outputs": [
-    {
-     "output_type": "stream",
-     "name": "stdout",
-     "text": [
-      "Apply Tokenization...\tdone!\n"
-     ]
-    }
-   ],
-   "source": [
-    "dataset_raw, labels = load_data(path=Config.Train)\n",
-    "dataset_tokenized = apply_tokenization(\n",
-    "    dataset=dataset_raw, tokenizer=tokenizer, method=PreProcessType.Base\n",
-    ")\n",
-    "dataset = REDataset(tokenized_dataset=dataset_tokenized, labels=labels)"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 29,
-   "metadata": {},
    "outputs": [],
    "source": [
-    "data_collator = DataCollatorForWholeWordMask(\n",
-    "        tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
-    "    )"
+    "pooler = output.last_hidden_state[:, 0, :]"
    ]
   },
   {
@@ -374,7 +137,7 @@
      "output_type": "execute_result",
      "data": {
       "text/plain": [
-       "DataCollatorForWholeWordMask(tokenizer=PreTrainedTokenizer(name_or_path='bert-base-multilingual-cased', vocab_size=119547, model_max_len=512, is_fast=False, padding_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}), mlm=True, mlm_probability=0.15)"
+       "torch.Size([4, 42])"
       ]
      },
      "metadata": {},
@@ -382,265 +145,118 @@
     }
    ],
    "source": [
-    "data_collator"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 15,
-   "metadata": {},
-   "outputs": [],
-   "source": [
-    "training_args = TrainingArguments(**TrainArgs.Base)"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 20,
-   "metadata": {},
-   "outputs": [],
-   "source": [
-    "trainer = Trainer(\n",
-    "    model=model,\n",
-    "    args=training_args,\n",
-    "    train_dataset=dataset,\n",
-    "    data_collator=data_collator\n",
-    ")"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 24,
-   "metadata": {},
-   "outputs": [
-    {
-     "output_type": "execute_result",
-     "data": {
-      "text/plain": [
-       "{'input_ids': tensor([   101,  50266,  11489,   9405,  24974,  24683,   9477,  90578,   9625,\n",
-       "         119376,  12692,  45725,   9651,  99183,  10459,   9376,  42771,  70186,\n",
-       "           9167,  15001,  11261,  41605,    113,  12001,  57836,    114,   9590,\n",
-       "           9706,  28396,    113,  13796,  19986,    114,   8843,  22634,    117,\n",
-       "           9638,   9376,  42771,  22879,   9651,  99183,  10459,   9684,  46520,\n",
-       "          11513,   9641, 119298,  11018,   9251,  11261,   9405,  24974, 118800,\n",
-       "          27792,  16139,    119,    102,      0,      0,      0,      0,      0,\n",
-       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
-       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
-       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
-       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
-       "              0]),\n",
-       " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
-       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
-       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
-       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
-       "         0, 0, 0, 0]),\n",
-       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
-       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
-       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
-       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
-       "         0, 0, 0, 0]),\n",
-       " 'labels': tensor(17)}"
-      ]
-     },
-     "metadata": {},
-     "execution_count": 24
-    }
-   ],
-   "source": [
-    "dataset[0]"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 35,
-   "metadata": {},
-   "outputs": [
-    {
-     "output_type": "execute_result",
-     "data": {
-      "text/plain": [
-       "{'input_ids': tensor([   101,  50266,  11489,   9405,  24974,  24683,   9477,  90578,   9625,\n",
-       "         119376,  12692,  45725,   9651,  99183,  10459,   9376,  42771,  70186,\n",
-       "           9167,  15001,  11261,  41605,    113,  12001,  57836,    114,   9590,\n",
-       "           9706,  28396,    113,  13796,  19986,    114,   8843,  22634,    117,\n",
-       "           9638,   9376,  42771,  22879,   9651,  99183,  10459,   9684,  46520,\n",
-       "          11513,   9641, 119298,  11018,   9251,  11261,   9405,  24974, 118800,\n",
-       "          27792,  16139,    119,    102,      0,      0,      0,      0,      0,\n",
-       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
-       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
-       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
-       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
-       "              0]),\n",
-       " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
-       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
-       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
-       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
-       "         0, 0, 0, 0]),\n",
-       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
-       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
-       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
-       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
-       "         0, 0, 0, 0]),\n",
-       " 'labels': tensor(17)}"
-      ]
-     },
-     "metadata": {},
-     "execution_count": 35
-    }
-   ],
-   "source": [
-    "label = dataset['labels'], dataset['labels']"
+    "model.classifier(pooler).size()"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 39,
+   "execution_count": 40,
    "metadata": {},
    "outputs": [],
    "source": [
-    "temp = data_collator(dataset)"
+    "class VanillaBert_v2(nn.Module):\n",
+    "    def __init__(\n",
+    "        self,\n",
+    "        model_type: str = ModelType.SequenceClf,  # BertForSequenceClassification\n",
+    "        pretrained_type: str = PreTrainedType.MultiLingual,  # bert-base-multilingual-cased\n",
+    "        num_labels: int = Config.NumClasses,  # 42\n",
+    "        pooler_idx: int = 0\n",
+    "    ):\n",
+    "        super(VanillaBert_v2, self).__init__()\n",
+    "        # BERT로부터 얻은 128(=max_length)개 hidden state 중 몇 번째를 활용할 지 결정. Default - 0(CLS 토큰의 인덱스)\n",
+    "        \n",
+    "        bert = self.load_bert(\n",
+    "            model_type=model_type,\n",
+    "            pretrained_type=pretrained_type,\n",
+    "        )\n",
+    "        self.backbone = bert.bert\n",
+    "        self.dropout = bert.dropout\n",
+    "        self.clf = bert.classifier\n",
+    "        self.idx = 0 if pooler_idx == 0 else pooler_idx\n",
+    "\n",
+    "    def forward(self, input_ids, token_type_ids, attention_mask):\n",
+    "        x = self.backbone(\n",
+    "            input_ids=input_ids,\n",
+    "            token_type_ids=token_type_ids,\n",
+    "            attention_mask=attention_mask,\n",
+    "        )\n",
+    "        x = x.last_hidden_state[:, self.idx, :]\n",
+    "        x = self.dropout(x)\n",
+    "        output = self.clf(x)\n",
+    "        return output\n",
+    "\n",
+    "    @staticmethod\n",
+    "    def load_bert(model_type, pretrained_type):\n",
+    "        config = BertConfig.from_pretrained(pretrained_type)\n",
+    "        config.num_labels = 42\n",
+    "        if model_type == ModelType.SequenceClf:\n",
+    "            model = BertForSequenceClassification.from_pretrained(pretrained_type, config=config)\n",
+    "        else:\n",
+    "            raise NotImplementedError()\n",
+    "\n",
+    "        return model"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 47,
+   "execution_count": 41,
    "metadata": {},
    "outputs": [
     {
-     "output_type": "execute_result",
-     "data": {
-      "text/plain": [
-       "'[CLS] 용병 공격수 [MASK] [MASK] [MASK] [MASK] [MASK] 초 활약한 강수일의 침체, 시즌 중반에 영입한 세르비아 출신 [MASK] [MASK] 미드필더 오그넨 코로만의 부상 [MASK] 부진의 원인으로 지적되던 [MASK] 인천은 시즌 [MASK] 4경기에서 3승 1패를 거두며 막판 승점 [MASK] [MASK] [MASK] [MASK] [MASK] 정규리그 순위 5위로 플레이오프 [SEP]'"
-      ]
-     },
-     "metadata": {},
-     "execution_count": 47
+     "output_type": "error",
+     "ename": "TypeError",
+     "evalue": "super(type, obj): obj must be an instance or subtype of type",
+     "traceback": [
+      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
+      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
+      "\u001b[0;32m<ipython-input-41-d30e761a58bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVanillaBert_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
+      "\u001b[0;32m<ipython-input-40-13a785c586b5>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_type, pretrained_type, num_labels, pooler_idx, dropout)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mdropout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     ):\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVanillaBert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;31m# BERT로부터 얻은 128(=max_length)개 hidden state 중 몇 번째를 활용할 지 결정. Default - 0(CLS 토큰의 인덱스)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpooler_idx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mpooler_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
+      "\u001b[0;31mTypeError\u001b[0m: super(type, obj): obj must be an instance or subtype of type"
+     ]
     }
    ],
    "source": [
-    "tokenizer.decode(temp['input_ids'][3])"
+    "model = VanillaBert_v2()"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 50,
+   "execution_count": 14,
    "metadata": {},
    "outputs": [
     {
      "output_type": "execute_result",
      "data": {
       "text/plain": [
-       "{'input_ids': tensor([   101,  50266,  11489,   9405,  24974,  24683,   9477,  90578,   9625,\n",
-       "         119376,  12692,  45725,   9651,  99183,  10459,   9376,  42771,  70186,\n",
-       "           9167,  15001,  11261,  41605,    113,  12001,  57836,    114,   9590,\n",
-       "           9706,  28396,    113,  13796,  19986,    114,   8843,  22634,    117,\n",
-       "           9638,   9376,  42771,  22879,   9651,  99183,  10459,   9684,  46520,\n",
-       "          11513,   9641, 119298,  11018,   9251,  11261,   9405,  24974, 118800,\n",
-       "          27792,  16139,    119,    102,      0,      0,      0,      0,      0,\n",
-       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
-       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
-       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
-       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
-       "              0]),\n",
-       " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
-       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
-       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
-       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
-       "         0, 0, 0, 0]),\n",
-       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
-       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
-       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
-       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
-       "         0, 0, 0, 0]),\n",
-       " 'labels': tensor(17)}"
+       "Dropout(p=0.1, inplace=False)"
       ]
      },
      "metadata": {},
-     "execution_count": 50
+     "execution_count": 14
     }
    ],
    "source": [
-    "dataset[0]"
+    "model.dropout"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 48,
+   "execution_count": 15,
    "metadata": {},
    "outputs": [
     {
      "output_type": "execute_result",
      "data": {
       "text/plain": [
-       "'[UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] 브랜드들은 [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] 일컫는 말로 [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]'"
+       "Linear(in_features=768, out_features=42, bias=True)"
       ]
      },
      "metadata": {},
-     "execution_count": 48
-    }
-   ],
-   "source": [
-    "tokenizer.decode(temp['labels'][0])"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": null,
-   "metadata": {},
-   "outputs": [],
-   "source": [
-    "data_collator()"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 21,
-   "metadata": {},
-   "outputs": [
-    {
-     "output_type": "error",
-     "ename": "ValueError",
-     "evalue": "Expected input batch_size (32) to match target batch_size (3200).",
-     "traceback": [
-      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
-      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
-      "\u001b[0;32m<ipython-input-21-3435b262f1ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
-      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model_path, trial)\u001b[0m\n\u001b[1;32m    886\u001b[0m                         \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m                     \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_total_flos\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating_point_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1248\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1250\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1252\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1275\u001b[0m         \u001b[0mSubclass\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0moverride\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcustom\u001b[0m \u001b[0mbehavior\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m         \"\"\"\n\u001b[0;32m-> 1277\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1278\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1511\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1512\u001b[0m                 \u001b[0mloss_fct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1513\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1515\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 948\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2420\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2421\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2422\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2214\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2215\u001b[0m         raise ValueError('Expected input batch_size ({}) to match target batch_size ({}).'\n\u001b[0;32m-> 2216\u001b[0;31m                          .format(input.size(0), target.size(0)))\n\u001b[0m\u001b[1;32m   2217\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2218\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;31mValueError\u001b[0m: Expected input batch_size (32) to match target batch_size (3200)."
-     ]
+     "execution_count": 15
     }
    ],
    "source": [
-    "trainer.train()"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": null,
-   "metadata": {},
-   "outputs": [],
-   "source": [
-    "training_args = TrainingArguments(**TrainArgs.Base)\n",
-    "\n",
-    "data_collaor = DataCollatorForLanguageModeling(\n",
-    "    tokenizer=tokenizer,\n",
-    "    mlm=True,\n",
-    "    mlm_probability=0.15)\n",
-    "\n",
-    "trainer = Trainer(\n",
-    "    model=model,\n",
-    "    args=training_args,\n",
-    "    data_collator=data_collator,\n",
-    "    train_dataset=dataset\n",
-    ")"
+    "model.classifier"
    ]
   }
  ]
diff --git a/notebooks/Sketch ESP.ipynb b/notebooks/Sketch ESP.ipynb
index 1864f96..24455d4 100644
--- a/notebooks/Sketch ESP.ipynb	
+++ b/notebooks/Sketch ESP.ipynb	
@@ -15,7 +15,7 @@
   "orig_nbformat": 2,
   "kernelspec": {
    "name": "python377jvsc74a57bd098b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f",
-   "display_name": "Python 3.7.7 64-bit"
+   "display_name": "Python 3.7.7 64-bit ('base': conda)"
   }
  },
  "nbformat": 4,
@@ -23,27 +23,32 @@
  "cells": [
   {
    "cell_type": "code",
-   "execution_count": 47,
+   "execution_count": 63,
    "metadata": {},
    "outputs": [],
    "source": [
     "import os\n",
     "import re\n",
     "import sys\n",
+    "from time import time\n",
     "import pandas as pd\n",
+    "from torch.utils.data import DataLoader\n",
+    "from pykospacing import spacing\n",
     "from transformers import BertTokenizer\n",
     "from konlpy.tag import Mecab\n",
+    "# from googletrans import LANGUAGES, Translator\n",
     "\n",
     "sys.path.insert(0, '../')\n",
-    "from dataset import REDataset, COLUMNS\n",
+    "from dataset import REDataset, COLUMNS, load_data\n",
     "from tokenization import load_tokenizer\n",
+    "from models import load_model\n",
     "from tokenization import SpecialToken as ST\n",
-    "from config import PreTrainedType, Config"
+    "from config import PreTrainedType, Config, ModelType"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 3,
+   "execution_count": 64,
    "metadata": {},
    "outputs": [
     {
@@ -57,248 +62,345 @@
     }
    ],
    "source": [
-    "data = REDataset()"
+    "dataset = REDataset(device='cpu')"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 7,
+   "execution_count": 65,
    "metadata": {},
    "outputs": [],
    "source": [
-    "tokenizer = BertTokenizer.from_pretrained(PreTrainedType.MultiLingual)"
+    "irrelavant = data[data['label'] == 0].reset_index(drop=True)"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 13,
+   "execution_count": 53,
    "metadata": {},
    "outputs": [
     {
      "output_type": "execute_result",
      "data": {
       "text/plain": [
-       "2"
-      ]
+       "                                         relation_state       e1  e1_start  \\\n",
+       "0     선거에서 민주당은 해산 전 의석인 230석에 한참 못 미치는 57석(지역구 27석,...      민주당         5   \n",
+       "1     이와 관련해 AFCD는 대학 소속 전문가와 세계동물보건기구(OIE)가 사람과 동물 ...      OIE        33   \n",
+       "2     김동양 NH투자증권 연구원은 “삼성SDS의 3분기 매출액은 2조6604억원, 영업이...    삼성SDS        17   \n",
+       "3     이후 구 공화당계와 유신정우회계 인사들은 김종철, 이만섭을 중심으로 한국국민당을 조...    유신정우회        11   \n",
+       "4     쇠뇌를 소지한 병사가 실전에 임한 것은 제3차 십자군 원정 때인데, 사자심왕 리처드...   리처드 1세        43   \n",
+       "...                                                 ...      ...       ...   \n",
+       "4427  사나다군과 모리군이 어떻게해서 이에야스 본인에까지 육박한 것에 대해 여러 설이 있어...     이에야스        17   \n",
+       "4428  김영삼 전 대통령은 2012년 7월 11일 김문수 새누리당 대선 경선후보의 예방에 ...      김문수        24   \n",
+       "4429  롱스트리트는 블랙장군의 휘하로 원군을 보낸다면 로즈크란즈의 부대를 오하이오주 방면으...    롱스트리트         0   \n",
+       "4430  2002년 FIFA 월드컵 사우디아라비아와의 1차전에서 독일은 8-0으로 승리하였는...  사우디아라비아        15   \n",
+       "4431  LG전자는 올해 초 국내시장에 출시한 2020년형 ‘LG 그램’ 시리즈를 이달부터 ...     LG전자         0   \n",
+       "\n",
+       "      e1_end       e2  e2_start  e2_end  label  \n",
+       "0          7      27석        42      44      0  \n",
+       "1         35      전문가        19      21      0  \n",
+       "2         21      10%        86      88      0  \n",
+       "3         15    한국국민당        38      42      0  \n",
+       "4         48  제3차 십자군        22      28      0  \n",
+       "...      ...      ...       ...     ...    ...  \n",
+       "4427      20     사나다군         0       3      0  \n",
+       "4428      26      박근혜        47      49      0  \n",
+       "4429       4       장군         9      10      0  \n",
+       "4430      21    2002년         0       4      0  \n",
+       "4431       3       북미        46      47      0  \n",
+       "\n",
+       "[4432 rows x 8 columns]"
+      ],
+      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>relation_state</th>\n      <th>e1</th>\n      <th>e1_start</th>\n      <th>e1_end</th>\n      <th>e2</th>\n      <th>e2_start</th>\n      <th>e2_end</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>선거에서 민주당은 해산 전 의석인 230석에 한참 못 미치는 57석(지역구 27석,...</td>\n      <td>민주당</td>\n      <td>5</td>\n      <td>7</td>\n      <td>27석</td>\n      <td>42</td>\n      <td>44</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>이와 관련해 AFCD는 대학 소속 전문가와 세계동물보건기구(OIE)가 사람과 동물 ...</td>\n      <td>OIE</td>\n      <td>33</td>\n      <td>35</td>\n      <td>전문가</td>\n      <td>19</td>\n      <td>21</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>김동양 NH투자증권 연구원은 “삼성SDS의 3분기 매출액은 2조6604억원, 영업이...</td>\n      <td>삼성SDS</td>\n      <td>17</td>\n      <td>21</td>\n      <td>10%</td>\n      <td>86</td>\n      <td>88</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>이후 구 공화당계와 유신정우회계 인사들은 김종철, 이만섭을 중심으로 한국국민당을 조...</td>\n      <td>유신정우회</td>\n      <td>11</td>\n      <td>15</td>\n      <td>한국국민당</td>\n      <td>38</td>\n      <td>42</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>쇠뇌를 소지한 병사가 실전에 임한 것은 제3차 십자군 원정 때인데, 사자심왕 리처드...</td>\n      <td>리처드 1세</td>\n      <td>43</td>\n      <td>48</td>\n      <td>제3차 십자군</td>\n      <td>22</td>\n      <td>28</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4427</th>\n      <td>사나다군과 모리군이 어떻게해서 이에야스 본인에까지 육박한 것에 대해 여러 설이 있어...</td>\n      <td>이에야스</td>\n      <td>17</td>\n      <td>20</td>\n      <td>사나다군</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4428</th>\n      <td>김영삼 전 대통령은 2012년 7월 11일 김문수 새누리당 대선 경선후보의 예방에 ...</td>\n      <td>김문수</td>\n      <td>24</td>\n      <td>26</td>\n      <td>박근혜</td>\n      <td>47</td>\n      <td>49</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4429</th>\n      <td>롱스트리트는 블랙장군의 휘하로 원군을 보낸다면 로즈크란즈의 부대를 오하이오주 방면으...</td>\n      <td>롱스트리트</td>\n      <td>0</td>\n      <td>4</td>\n      <td>장군</td>\n      <td>9</td>\n      <td>10</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4430</th>\n      <td>2002년 FIFA 월드컵 사우디아라비아와의 1차전에서 독일은 8-0으로 승리하였는...</td>\n      <td>사우디아라비아</td>\n      <td>15</td>\n      <td>21</td>\n      <td>2002년</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4431</th>\n      <td>LG전자는 올해 초 국내시장에 출시한 2020년형 ‘LG 그램’ 시리즈를 이달부터 ...</td>\n      <td>LG전자</td>\n      <td>0</td>\n      <td>3</td>\n      <td>북미</td>\n      <td>46</td>\n      <td>47</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>4432 rows × 8 columns</p>\n</div>"
      },
      "metadata": {},
-     "execution_count": 13
+     "execution_count": 53
     }
    ],
    "source": [
-    "special_tokens_dict = {\n",
-    "    'additional_special_tokens': [ST.E1Open, ST.E1Close, ST.E2Open, ST.E2Close]}\n",
-    "tokenizer.add_special_tokens(special_tokens_dict)"
+    "irrelavant"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 14,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "loader = DataLoader(dataset, batch_size=4)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 15,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "for sents, labels in loader:\n",
+    "    break"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 36,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "loss, outputs = model(**sents, labels=labels).values()"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 72,
+   "execution_count": 38,
    "metadata": {},
    "outputs": [
     {
      "output_type": "execute_result",
      "data": {
       "text/plain": [
-       "'영국에서 사용되는 스포츠 유틸리티 자동차의 브랜드로는 랜드로버(Land Rover)와 지프(Jeep)가 있으며, 이 브랜드들은 자동차의 종류를 일컫는 말로 사용되기도 한다.'"
+       "tensor([[-0.2576,  0.0415, -0.0403, -0.1123, -0.0196, -0.1867,  0.0522, -0.1830,\n",
+       "         -0.1118, -0.1232,  0.0412, -0.0852, -0.1258,  0.0886,  0.0677,  0.0340,\n",
+       "         -0.1190,  0.1963,  0.1283,  0.0847,  0.0378, -0.0813,  0.0798,  0.0308,\n",
+       "         -0.1249, -0.0688, -0.1100, -0.0185, -0.0520,  0.0494,  0.0492,  0.1050,\n",
+       "         -0.1278,  0.0104, -0.1069,  0.1565,  0.0253,  0.0362, -0.0573,  0.1551,\n",
+       "         -0.1461, -0.1355],\n",
+       "        [-0.1006,  0.1558,  0.1570, -0.1249, -0.0013, -0.2368,  0.0351, -0.1673,\n",
+       "         -0.0706, -0.0630, -0.0654,  0.0985, -0.2683,  0.2805, -0.0239,  0.1307,\n",
+       "         -0.0509,  0.1575, -0.0761,  0.2519,  0.2930, -0.2371,  0.0665, -0.0909,\n",
+       "          0.0248, -0.1902, -0.0675, -0.1522,  0.1778,  0.0296, -0.0176,  0.1829,\n",
+       "          0.0697,  0.1478, -0.0558,  0.1785, -0.0739, -0.1009,  0.0863,  0.1146,\n",
+       "         -0.1634, -0.1050],\n",
+       "        [-0.2248,  0.0539,  0.0282, -0.1621, -0.0597, -0.1486,  0.0701, -0.1567,\n",
+       "         -0.1493, -0.0685, -0.0360, -0.0085, -0.0343,  0.0839,  0.0538, -0.0777,\n",
+       "         -0.0446,  0.1628, -0.0575,  0.1605,  0.0431, -0.1223, -0.0178,  0.2244,\n",
+       "         -0.0866, -0.1345, -0.1241,  0.0264, -0.0023,  0.0495,  0.0486,  0.0752,\n",
+       "         -0.0446,  0.0979,  0.0509,  0.2971,  0.0803,  0.0771,  0.0098,  0.1750,\n",
+       "         -0.1635, -0.0715],\n",
+       "        [-0.2944,  0.0483,  0.0210, -0.1458, -0.0538, -0.2169,  0.1477, -0.1319,\n",
+       "         -0.1317, -0.0788, -0.0310, -0.1035,  0.0413,  0.1764,  0.0946, -0.0385,\n",
+       "         -0.0888,  0.2171,  0.0420,  0.1125,  0.1233, -0.0101, -0.0034,  0.0533,\n",
+       "          0.0488, -0.0704, -0.0334, -0.1307,  0.0680,  0.0206,  0.0542,  0.0947,\n",
+       "         -0.0465,  0.0714, -0.0466,  0.2024,  0.0167,  0.0194,  0.0379,  0.0630,\n",
+       "         -0.1309, -0.0602]], grad_fn=<AddmmBackward>)"
       ]
      },
      "metadata": {},
-     "execution_count": 72
+     "execution_count": 38
     }
    ],
    "source": [
-    "sample"
+    "outputs"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 102,
+   "execution_count": 21,
    "metadata": {},
    "outputs": [
     {
      "output_type": "execute_result",
      "data": {
       "text/plain": [
-       "<re.Match object; span=(34, 46), match='(Land Rover)'>"
+       "tensor(3.7061, grad_fn=<NllLossBackward>)"
       ]
      },
      "metadata": {},
-     "execution_count": 102
+     "execution_count": 21
     }
    ],
    "source": [
-    "re.search(r\"\\([a-zA-Z가-힣0-9\\s?]+\\)\", sample)"
+    "output.loss"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 20,
-   "metadata": {},
-   "outputs": [],
-   "source": []
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 70,
+   "execution_count": 34,
    "metadata": {},
    "outputs": [],
    "source": [
-    "raw = pd.read_csv(Config.Train, sep='\\t', header=None, names=COLUMNS)\n",
-    "raw = raw.drop(['id'], axis=1)"
+    "a, b = output.values()"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 104,
+   "execution_count": 35,
    "metadata": {},
-   "outputs": [],
+   "outputs": [
+    {
+     "output_type": "execute_result",
+     "data": {
+      "text/plain": [
+       "tensor([[-0.1884,  0.1002,  0.0080, -0.1926, -0.0929, -0.2002,  0.1053, -0.2207,\n",
+       "          0.0040, -0.0709, -0.0488, -0.0330, -0.1938,  0.1910,  0.0389, -0.0190,\n",
+       "         -0.0605,  0.2034,  0.0611,  0.0753,  0.0798, -0.1167,  0.1096,  0.0070,\n",
+       "         -0.0777, -0.1542, -0.1193, -0.1325,  0.0406, -0.0190,  0.0598,  0.1240,\n",
+       "         -0.0067,  0.1166, -0.1306,  0.2776,  0.0656, -0.0752,  0.0817,  0.0865,\n",
+       "         -0.1244, -0.1109],\n",
+       "        [-0.1549,  0.1705,  0.0495, -0.0540, -0.0843, -0.1717,  0.0775, -0.1785,\n",
+       "         -0.1004,  0.0228, -0.0049, -0.0520, -0.0769,  0.1905,  0.0623,  0.0853,\n",
+       "         -0.0525,  0.2831, -0.0504,  0.2236,  0.0913, -0.2786,  0.0249,  0.1152,\n",
+       "         -0.1319, -0.0654, -0.1120,  0.0092,  0.0649, -0.0491,  0.0654,  0.1766,\n",
+       "         -0.0360, -0.0084, -0.0500,  0.1527, -0.0202, -0.0326,  0.1777,  0.2141,\n",
+       "         -0.0242, -0.0608],\n",
+       "        [-0.1574,  0.0213,  0.0968, -0.1638, -0.0426, -0.2851,  0.0577, -0.1240,\n",
+       "         -0.1844, -0.0767, -0.1093, -0.0350, -0.1997,  0.1597, -0.0380,  0.2394,\n",
+       "         -0.1176,  0.1643, -0.0835,  0.0819,  0.2020, -0.1839,  0.0656,  0.1710,\n",
+       "         -0.0504, -0.0770, -0.0708,  0.1418,  0.0698, -0.0602,  0.2979,  0.0113,\n",
+       "          0.0547, -0.0388, -0.0291,  0.3736,  0.0136,  0.0113,  0.0551,  0.2149,\n",
+       "         -0.1297, -0.1422],\n",
+       "        [-0.2692,  0.1237,  0.0442, -0.1759, -0.0145, -0.2449,  0.1198, -0.2492,\n",
+       "         -0.1359, -0.1840, -0.0072, -0.1351, -0.0715,  0.1551,  0.0501, -0.0101,\n",
+       "         -0.0925,  0.2537,  0.0109,  0.1269,  0.1853, -0.1978,  0.0560,  0.0438,\n",
+       "         -0.0642, -0.1249, -0.0606, -0.1351,  0.0292,  0.0896,  0.1315,  0.0254,\n",
+       "         -0.0591,  0.0483,  0.0228,  0.2731, -0.0747,  0.0592,  0.0061,  0.1846,\n",
+       "         -0.0879, -0.0051]], grad_fn=<AddmmBackward>)"
+      ]
+     },
+     "metadata": {},
+     "execution_count": 35
+    }
+   ],
    "source": [
-    "tagger = Mecab()"
+    "b"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 108,
+   "execution_count": 5,
    "metadata": {},
    "outputs": [],
    "source": [
-    "raw['tokenized'] = raw['relation_state'].apply(lambda x: tagger.pos(x))"
+    "raw = pd.read_csv(Config.Train, sep='\\t', header=None, names=COLUMNS)\n",
+    "raw = raw.drop(['id'], axis=1)\n",
+    "tokenizer = BertTokenizer.from_pretrained(PreTrainedType.MultiLingual)\n",
+    "sample = raw['relation_state'].tolist()[0]\n"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 115,
+   "execution_count": 3,
    "metadata": {},
-   "outputs": [],
+   "outputs": [
+    {
+     "output_type": "execute_result",
+     "data": {
+      "text/plain": [
+       "4"
+      ]
+     },
+     "metadata": {},
+     "execution_count": 3
+    }
+   ],
    "source": [
-    "IDX = 1\n",
-    "sample = data.data['relation_state'].tolist()[IDX]\n",
-    "sample_pos = tagger.pos(sample)"
+    "special_tokens_dict = {\n",
+    "    'additional_special_tokens': [ST.E1Open, ST.E1Close, ST.E2Open, ST.E2Close]}\n",
+    "tokenizer.add_special_tokens(special_tokens_dict)"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 117,
+   "execution_count": 18,
    "metadata": {},
    "outputs": [
     {
-     "output_type": "execute_result",
-     "data": {
-      "text/plain": [
-       "                                      relation_state        e1  e1_start  \\\n",
-       "0  영국에서 사용되는 스포츠 유틸리티 자동차의 브랜드로는 랜드로버(Land Rover)...      랜드로버        30   \n",
-       "1  선거에서 민주당은 해산 전 의석인 230석에 한참 못 미치는 57석(지역구 27석,...       민주당         5   \n",
-       "2  유럽 축구 연맹(UEFA) 집행위원회는 2014년 1월 24일에 열린 회의를 통해 ...  유럽 축구 연맹         0   \n",
-       "3  용병 공격수 챠디의 부진과 시즌 초 활약한 강수일의 침체, 시즌 중반에 영입한 세르...       강수일        24   \n",
-       "4  람캄행 왕은 1237년에서 1247년 사이 수코타이의 왕 퍼쿤 씨 인트라팃과 쓰엉 ...       람캄행         0   \n",
-       "\n",
-       "   e1_end         e2  e2_start  e2_end  label  \\\n",
-       "0      33        자동차        19      21     17   \n",
-       "1       7        27석        42      44      0   \n",
-       "2       7       UEFA         9      12      6   \n",
-       "3      26        공격수         3       5      2   \n",
-       "4       2  퍼쿤 씨 인트라팃        32      40      8   \n",
-       "\n",
-       "                                               input  \n",
-       "0  영국에서 사용되는 스포츠 유틸리티 자동차의 브랜드로는 랜드로버(Land Rover)...  \n",
-       "1  선거에서 민주당은 해산 전 의석인 230석에 한참 못 미치는 57석(지역구 27석,...  \n",
-       "2  유럽 축구 연맹(UEFA) 집행위원회는 2014년 1월 24일에 열린 회의를 통해 ...  \n",
-       "3  용병 공격수 챠디의 부진과 시즌 초 활약한 강수일의 침체, 시즌 중반에 영입한 세르...  \n",
-       "4  람캄행 왕은 1237년에서 1247년 사이 수코타이의 왕 퍼쿤 씨 인트라팃과 쓰엉 ...  "
-      ],
-      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>relation_state</th>\n      <th>e1</th>\n      <th>e1_start</th>\n      <th>e1_end</th>\n      <th>e2</th>\n      <th>e2_start</th>\n      <th>e2_end</th>\n      <th>label</th>\n      <th>input</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>영국에서 사용되는 스포츠 유틸리티 자동차의 브랜드로는 랜드로버(Land Rover)...</td>\n      <td>랜드로버</td>\n      <td>30</td>\n      <td>33</td>\n      <td>자동차</td>\n      <td>19</td>\n      <td>21</td>\n      <td>17</td>\n      <td>영국에서 사용되는 스포츠 유틸리티 자동차의 브랜드로는 랜드로버(Land Rover)...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>선거에서 민주당은 해산 전 의석인 230석에 한참 못 미치는 57석(지역구 27석,...</td>\n      <td>민주당</td>\n      <td>5</td>\n      <td>7</td>\n      <td>27석</td>\n      <td>42</td>\n      <td>44</td>\n      <td>0</td>\n      <td>선거에서 민주당은 해산 전 의석인 230석에 한참 못 미치는 57석(지역구 27석,...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>유럽 축구 연맹(UEFA) 집행위원회는 2014년 1월 24일에 열린 회의를 통해 ...</td>\n      <td>유럽 축구 연맹</td>\n      <td>0</td>\n      <td>7</td>\n      <td>UEFA</td>\n      <td>9</td>\n      <td>12</td>\n      <td>6</td>\n      <td>유럽 축구 연맹(UEFA) 집행위원회는 2014년 1월 24일에 열린 회의를 통해 ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>용병 공격수 챠디의 부진과 시즌 초 활약한 강수일의 침체, 시즌 중반에 영입한 세르...</td>\n      <td>강수일</td>\n      <td>24</td>\n      <td>26</td>\n      <td>공격수</td>\n      <td>3</td>\n      <td>5</td>\n      <td>2</td>\n      <td>용병 공격수 챠디의 부진과 시즌 초 활약한 강수일의 침체, 시즌 중반에 영입한 세르...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>람캄행 왕은 1237년에서 1247년 사이 수코타이의 왕 퍼쿤 씨 인트라팃과 쓰엉 ...</td>\n      <td>람캄행</td>\n      <td>0</td>\n      <td>2</td>\n      <td>퍼쿤 씨 인트라팃</td>\n      <td>32</td>\n      <td>40</td>\n      <td>8</td>\n      <td>람캄행 왕은 1237년에서 1247년 사이 수코타이의 왕 퍼쿤 씨 인트라팃과 쓰엉 ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
-     },
-     "metadata": {},
-     "execution_count": 117
+     "output_type": "error",
+     "ename": "AttributeError",
+     "evalue": "'NoneType' object has no attribute 'group'",
+     "traceback": [
+      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
+      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
+      "\u001b[0;32m<ipython-input-18-be808d9f7116>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtranslator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'안녕하세요'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
+      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/googletrans/client.py\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(self, text, dest, src, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0morigin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_translate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;31m# this code will be updated when the format is changed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
+      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/googletrans/client.py\u001b[0m in \u001b[0;36m_translate\u001b[0;34m(self, text, dest, src, override)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_translate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverride\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_acquirer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         params = utils.build_params(query=text, src=src, dest=dest,\n\u001b[1;32m     80\u001b[0m                                     token=token, override=override)\n",
+      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/googletrans/gtoken.py\u001b[0m in \u001b[0;36mdo\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m         \u001b[0mtk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
+      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/googletrans/gtoken.py\u001b[0m in \u001b[0;36m_update\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# this will be the same as python code after stripping out a reserved word 'var'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRE_TKK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'var '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;31m# unescape special ascii characters such like a \\x3d(=)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unicode-escape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
+      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"
+     ]
     }
    ],
    "source": [
-    "data.data.head()"
+    "translator.translate('안녕하세요')"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 116,
+   "execution_count": 64,
    "metadata": {},
    "outputs": [
     {
      "output_type": "execute_result",
      "data": {
       "text/plain": [
-       "'선거에서 민주당은 해산 전 의석인 230석에 한참 못 미치는 57석(지역구 27석, 비례대표 30석)을 획득하는 데 그쳤다.'"
+       "'영국에서 사용되는 스포츠 유틸리티 자동차의 브랜드로는 랜드로버Land Rover와 지프Jeep가 있으며 이 브랜드들은 자동차의 종류를 일컫는 말로 사용되기도 한다.'"
       ]
      },
      "metadata": {},
-     "execution_count": 116
+     "execution_count": 64
     }
    ],
    "source": [
-    "sample"
+    "# 특수문자만 선택\n",
+    "re.sub(r\"[^\\.\\s가-힣ㄱ-ㅎㅏ-ㅣa-zA-Z0-9]\", '', sample)"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 114,
+   "execution_count": 49,
    "metadata": {},
    "outputs": [
     {
      "output_type": "execute_result",
      "data": {
       "text/plain": [
-       "[('영국', 'NNP'),\n",
-       " ('에서', 'JKB'),\n",
-       " ('사용', 'NNG'),\n",
-       " ('되', 'XSV'),\n",
-       " ('는', 'ETM'),\n",
-       " ('스포츠', 'NNG'),\n",
-       " ('유틸리티', 'NNG'),\n",
-       " ('자동차', 'NNG'),\n",
-       " ('의', 'JKG'),\n",
-       " ('브랜드', 'NNG'),\n",
-       " ('로', 'JKB'),\n",
-       " ('는', 'JX'),\n",
-       " ('랜', 'NNG'),\n",
-       " ('드로버', 'NNP'),\n",
-       " ('(', 'SSO'),\n",
-       " ('Land', 'SL'),\n",
-       " ('Rover', 'SL'),\n",
-       " (')', 'SSC'),\n",
-       " ('와', 'JC'),\n",
-       " ('지프', 'NNG'),\n",
-       " ('(', 'SSO'),\n",
-       " ('Jeep', 'SL'),\n",
-       " (')', 'SSC'),\n",
-       " ('가', 'JKS'),\n",
-       " ('있', 'VA'),\n",
-       " ('으며', 'EC'),\n",
-       " (',', 'SC'),\n",
-       " ('이', 'MM'),\n",
-       " ('브랜드', 'NNG'),\n",
-       " ('들', 'XSN'),\n",
-       " ('은', 'JX'),\n",
-       " ('자동차', 'NNG'),\n",
-       " ('의', 'JKG'),\n",
-       " ('종류', 'NNG'),\n",
-       " ('를', 'JKO'),\n",
-       " ('일컫', 'VV'),\n",
-       " ('는', 'ETM'),\n",
-       " ('말', 'NNG'),\n",
-       " ('로', 'JKB'),\n",
-       " ('사용', 'NNG'),\n",
-       " ('되', 'XSV'),\n",
-       " ('기', 'ETN'),\n",
-       " ('도', 'JX'),\n",
-       " ('한다', 'VV+EF'),\n",
-       " ('.', 'SF')]"
+       "'영국에서 사용되는 스포츠 유틸리티 자동차의 브랜드로는 랜드로버와 지프가 있으며, 이 브랜드들은 자동차의 종류를 일컫는 말로 사용되기도 한다.'"
       ]
      },
      "metadata": {},
-     "execution_count": 114
+     "execution_count": 49
     }
    ],
    "source": [
-    "['NNG', 'NNP' 'NNB' 'NNBC' 'NR' 'NP' 'VV' 'VA' 'XR']"
+    "# 괄호와 괄호 안의 문자 제거\n",
+    "re.sub(r\"\\([^)]*\\)\", '', sample)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 4,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "raw['relation_state'] = raw['relation_state'].apply(lambda x: re.sub(r\"\\([^)]*\\)\", '', x))\n",
+    "raw['relation_state'] = raw['relation_state'].apply(lambda x: re.sub(r\"[^\\.\\s가-힣ㄱ-ㅎㅏ-ㅣa-zA-Z0-9]\", '', x))\n",
+    "raw['relation_state'] = raw['relation_state'].apply(lambda x: x.replace(' ', ''))"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 73,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "raw['relation_state'] = raw['relation_state'].apply(lambda x: spacing(x))"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "raw.head()"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "asdf"
    ]
   }
  ]
diff --git a/requirements.txt b/requirements.txt
index c473563..0509457 100644
--- a/requirements.txt
+++ b/requirements.txt
@@ -6,4 +6,5 @@ fire==0.4.0
 transformers==4.2.0
 g2pK==0.9.4
 konlpy==0.5.2
-adamp==0.3.0
\ No newline at end of file
+adamp==0.3.0
+pykospacing @ git+https://github.com/haven-jeon/PyKoSpacing.git@1a36be492cc396559e7dce7825843af020ea231f
\ No newline at end of file
diff --git a/tokenization.py b/tokenization.py
index e27ad8d..5aa421e 100644
--- a/tokenization.py
+++ b/tokenization.py
@@ -9,18 +9,16 @@ class SpecialToken:
     SEP: str = "[SEP]"
     CLS: str = "[CLS]"
 
+    # 무엇(entity)은 무엇(entity)과 어떤 관계이다.
+    EOpen: str = "[ENT]"
+    EClose: str = "[/ENT]"
+    
     # 무엇(entity1)은 무엇(entity2)과 어떤 관계이다.
     E1Open: str = "[E1]"
     E1Close: str = "[/E1]"
     E2Open: str = "[E2]"
     E2Close: str = "[/E2]"
-
-    # 무엇(sub)은 무엇(obj)과 어떤 관계이다.
-    SUBOpen: str = "[SUB]"
-    SUBClose: str = "[/SUB]"
-    OBJOpen: str = "[OBJ]"
-    OBJClose: str = "[/OBJ]"
-
+    
 
 def load_tokenizer(type: str = PreProcessType.Base):
     """사전 학습된 tokenizer를 불러오는 함수
diff --git a/train.py b/train.py
index 3ce9f64..20b026e 100644
--- a/train.py
+++ b/train.py
@@ -277,7 +277,7 @@ if __name__ == "__main__":
     LOAD_STATE_DICT = None
 
     parser = argparse.ArgumentParser()
-    parser.add_argument("--model-type", type=str, default=ModelType.SequenceClf)
+    parser.add_argument("--model-type", type=str, default=ModelType.VanillaBert_v2)
     parser.add_argument(
         "--pretrained-type", type=str, default=PreTrainedType.MultiLingual
     )
diff --git a/wandb/latest-run b/wandb/latest-run
index f1bf844..c44d528 120000
--- a/wandb/latest-run
+++ b/wandb/latest-run
@@ -1 +1 @@
-run-20210418_123951-2v936pyt
\ No newline at end of file
+run-20210419_041444-3gt7of4n
\ No newline at end of file
